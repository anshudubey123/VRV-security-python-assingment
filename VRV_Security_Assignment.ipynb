import re
import csv
import pandas as pd
from collections import defaultdict

# Threshold for failed login attempts to consider an IP suspicious
FAILED_LOGIN_THRESHOLD = 10
LOG_FILE = "sample.log"  # Log file to be analyzed
OUTPUT_CSV = "log_analysis_results.csv"  # Output CSV file for results

def parse_log(log_lines):
    """
    Parses log lines and extracts relevant data using regex.
    
    Args:
        log_lines (list): List of log lines to parse.
    
    Returns:
        list: A list of dictionaries containing parsed log data.
    """
    data = []
    # Regex pattern to match log entries
    log_pattern = (
        r'^(?P<ip>\d+\.\d+\.\d+\.\d+) - - '
        r'(?P<timestamp>[^]]+)\] '
        r'"(?P<method>[A-Z]+) (?P<endpoint>\S+) HTTP/[0-9.]+" (?P<status>\d+) (?P<size>\d+)(?: ".*")?$'
    )
    for line in log_lines:
        match = re.match(log_pattern, line)  # Match the line against the regex pattern
        if match:
            data.append(match.groupdict())  # Append matched data as a dictionary
    return data

def count_requests_per_ip(log_lines):
    """
    Counts the number of requests made by each IP address.
    
    Args:
        log_lines (list): List of log lines to analyze.
    
    Returns:
        list: A sorted list of tuples (IP, count) in descending order of count.
    """
    ip_count = defaultdict(int)  # Dictionary to hold IP counts
    for line in log_lines:
        match = re.search(r'^(\d+\.\d+\.\d+\.\d+)', line)  # Extract IP address
        if match:
            ip_count[match.group(1)] += 1  # Increment count for the IP
    return sorted(ip_count.items(), key=lambda x: x[1], reverse=True)  # Sort by count

def most_frequently_accessed_endpoint(log_lines):
    """
    Finds the most frequently accessed endpoint from the log lines.
    
    Args:
        log_lines (list): List of log lines to analyze.
    
    Returns:
        tuple: The most accessed endpoint and its access count.
    """
    endpoint_count = defaultdict(int)  # Dictionary to hold endpoint counts
    for line in log_lines:
        match = re.search(r'"[A-Z]+ (\S+) HTTP/', line)  # Extract endpoint
        if match:
            endpoint_count[match.group(1)] += 1  # Increment count for the endpoint
    most_accessed = max(endpoint_count.items(), key=lambda x: x[1])  # Find the max accessed endpoint
    return most_accessed

def detect_suspicious_activity(log_lines):
    """
    Detects suspicious activity based on failed login attempts.
    
    Args:
        log_lines (list): List of log lines to analyze.
    
    Returns:
        dict: A dictionary of IP addresses with failed login counts exceeding the threshold.
    """
    failed_logins = defaultdict(int)  # Dictionary to hold failed login counts
    for line in log_lines:
        if '401' in line or 'Invalid credentials' in line:  # Check for failed login indicators
            match = re.search(r'^(\d+\.\d+\.\d+\.\d+)', line)  # Extract IP address
            if match:
                failed_logins[match.group(1)] += 1  # Increment count for the IP
    # Filter IPs with failed login counts exceeding the threshold
    suspicious_ips = {ip: count for ip, count in failed_logins.items() if count > FAILED_LOGIN_THRESHOLD}
    return suspicious_ips

def save_to_csv(requests_per_ip, most_accessed, suspicious_ips):
    """
    Saves the analysis results to a CSV file.
    
    Args:
        requests_per_ip (list): List of IP addresses and their request counts.
        most_accessed (tuple): The most accessed endpoint and its count.
        suspicious_ips (dict): Dictionary of suspicious IPs and their failed login counts.
    """
    with open(OUTPUT_CSV, mode='w', newline='') as file:
        writer = csv.writer(file)

        # Write requests per IP
        writer.writerow(["IP Address", "Request Count"])
        writer.writerows(requests_per_ip)

        # Write most accessed endpoint
        writer.writerow([])
            "              ip                    datetime method   endpoint  status  size\n",
            "0    192.168.1.1  03/Dec/2024:10:12:34 +0000    GET      /home     200   512\n",
            "1    203.0.113.5  03/Dec/2024:10:12:35 +0000   POST     /login     401   128\n",
            "2       10.0.0.2  03/Dec/2024:10:12:36 +0000    GET     /about     200   256\n",
            "3    192.168.1.1  03/Dec/2024:10:12:37 +0000    GET   /contact     200   312\n",
            "4  198.51.100.23  03/Dec/2024:10:12:38 +0000   POST  /register     200   128\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34 entries, 0 to 33\n",
            "Data columns (total 6 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   ip        34 non-null     object\n",
            " 1   datetime  34 non-null     object\n",
            " 2   method    34 non-null     object\n",
            " 3   endpoint  34 non-null     object\n",
            " 4   status    34 non-null     int64 \n",
            " 5   size      34 non-null     int64 \n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 1.7+ KB\n",
            "None\n",
            "\n",
            "Requests per IP:\n",
            "203.0.113.5: 8\n",
            "198.51.100.23: 8\n",
            "192.168.1.1: 7\n",
            "10.0.0.2: 6\n",
            "192.168.1.100: 5\n",
            "\n",
            "Most Frequently Accessed Endpoint:\n",
            "/login accessed 13 times\n",
            "\n",
            "Suspicious Activity Detected:\n"
          ]
        }
      ]
    }
  ]
}
